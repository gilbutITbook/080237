# TensorFlow.js 예제: 훈련 후 가중치 양자화 효과

훈련 후 양자화는 모델을 웹이나 모바일 장치 같이 저장 공간이 부족한 환경에 배포할 때 유용한 모델 크기 감소 기술입니다.
TensorFlow.js의 [컨버터 모듈](https://github.com/tensorflow/tfjs-converter)은
훈련이 끝난 모델의 가중치 정밀도를 16비트와 8비트 정수로 줄일 수 있습니다.
이는 모델 크기를 약 50%와 75% 정도로 줄입니다.

다음은 16비트 양자화와 8비트 양자화의 가중치 값 이산화를 이해하기 위한 그림입니다.
이 그림은 sine 곡선을 확대한 것입니다.

![가중치 양자화: 16비트와 8비트](./quantization.png)

이 예제는 가중치 양자화가 모델의 예측 정확도에 미치는 영향에 초점을 맞춥니다.

## 데모 소개

이 양자화 데모는 네 개의 예제로 구성됩니다:
1. housing: 이 데모는 다층 퍼셉트론 회귀 모델의 성능에 대한 양자화 영향을 평가합니다.
2. mnist: 이 데모는 MNIST 손글씨 숫자 데이터셋에서 훈련한 비교적 작은 심층 합성곱 신경망의 정확도에 대한
   양자화의 요과를 평가합니다. 양자화를 사용하지 않고 이 합성곱 신경망은
   거의 완벽한(즉 ~99.5%) 테스트 정확도를 달성할 수 있습니다.
3. fashion-mnist: 이 데모는 MNIST 보다 조금 더 어려운 패션 MNIST 데이터셋에서 훈련한 작은 심층 합성곱 신경망의
   정확도에 대한 양자화의 영향을 평가합니다. 양자화를 적용하지 않은 원본 모델의 정확도는 92~93%입니다.
4. MobileNetV2: 이 데모는 MobeilNetV2(너비 = 1.0)의 양자화된 버전과 양자화되지 않은 버전을
   [ImageNet](http://www.image-net.org/) 데이터셋에 있는 1,000개 이미지로 평가합니다.
   이 샘플은 https://github.com/ajschumacher/imagen 을 기반으로 합니다.

처음 세 개의 데모에서 16비트나 8비트 가중치 양자화는 정확도에 큰 영향을 미치지 않습니다.
하지만 MobileNetV2 데모에서는 8비트 가중치 양자화는 top-1과 top-5 정확도를 크게 감소시킵니다.
다음 표에 결과가 나타나있습니다:

| 데이터셋과 모델      | 원본 (양자화 없음) | 16비트 양자화 | 8비트 양자화 |
| ---------------------- | -------------------------- | ------------------- | ------------------ |
| housing: MLP 회귀 모델  |  MAE=0.311984     | MAE=0.311983        | MAE=0.312780       |
| MNIST: 합성곱 신경망         | 정확도=0.9952            | 정확도=0.9952     | 정확도=0.9952    |
| 패션 MNIST: 합성곱 신경망 | 정확도=0.922             | 정확도=0.922      | 정확도=0.9211    |
| MobileNetV2            | top-1 정확도=0.618; top-5 정확도=0.788 | top-1 정확도=0.624; top-5 정확도=0.789 | top-1 정확도=0.280; top-5 정확도=0.490 |

MAE는 평균 절댓값 오차입니다(낮을수록 좋습니다).

이 데모는 동일한 양자화 기술이 문제마다 미치는 영향이 다르다는 것을 보여줍니다.

### gzip 압축 비율에 대한 양자화 효과

양자화로 모델의 크기가 영향을 받는 또 다른 요소는 gzip 비율입니다.
gzip이 웹에서 대용량 파일을 전송하는데 널리 사용되기 때문에 중요하게 고려되어야 합니다.

양자화되지 않은 대부분의 모델(즉 32비트 부동 소수점 가중치를 가진 모델)은 가중치 파라미터에
잡음과 같은 변동이 있어 반복되는 패턴이 드물기 때문에 압축률이 좋지 않습니다.
16비트 정밀도로 양자화된 가중치를 가진 모델도 마찬가지입니다.
하지만 8비트 정밀도로 모델을 양자화하면 gzip 압출 비율을 크게 높일 수 있습니다.
이 예제의 `yarn quantize-and-evalute*` 명령(아래 참조)은 정확도를 평가할 뿐만 아니라
여러 양자화 수준에서 모델 파일의 gzip 압축 비율을 계산합니다.
다음 테이블은 이 예제에서 다루는 네 가지 모델의 압축 비율을 요약한 것입니다(높을수록 좋습니다):

gzip 압축 비율:
`(model.json과 가중치 파일의 전체 크기) / (gzip 압축된 크기)`

| 모델      | 원본 (양자화 없음) | 16비트 양자화 | 8비트 양자화 |
| ---------- | -------------------------- | ------------------- | ------------------ |
| housing: MLP 회귀 모델  | 1.121 | 1.161               | 1.388              |
| MNIST: 합성곱 신경망         | 1.082          | 1.037               | 1.184              |
| 패션 MNIST: 합성곱 신경망 | 1.078          | 1.048               | 1.229              |
| MobileNetV2            | 1.085          | 1.063               | 1.271              |

## housing 양자화 데모

준비:

```sh
yarn
```

처음부터 모델을 훈련하고 저장하기:
```sh
yarn train-housing
```

[CUDA 지원](https://www.tensorflow.org/install/install_linux) GPU를 가진 리눅스 시스템에서 실행한다면
다음 명령을 사용하세요:

```sh
yarn train-housing --gpu
```

`yarn train` 단계에서 저장한 모델에 양자화를 수행하고 모델의 테스트 정확도에 대한 영향을 평가하기:

```
yarn quantize-and-evaluate-housing
```

## MNIST 양자화 데모

준비:

```sh
yarn
```

처음부터 모델을 훈련하고 저장하기:
```sh
yarn train-mnist
```

또는 CUDA 가속 사용하기:

```sh
yarn train-mnist --gpu
```

`yarn train` 단계에서 저장한 모델에 양자화를 수행하고 모델의 테스트 정확도에 대한 영향을 평가하기:

```
yarn quantize-and-evaluate-mnist
```

이 명령은 여러 가지 양자화 수준(양자화 없음, 16비트, 8비트)에서 모델 파일의 gzip 압축 비율을 계산합니다.

## 패션-MNIST 양자화 데모

준비:

```sh
yarn
```

처음부터 모델을 훈련하고 저장하기:
```sh
yarn train-fashion-mnist
```

또는 CUDA 가속 사용하기:

```sh
yarn train-fashion-mnist --gpu
```

`yarn train` 단계에서 저장한 모델에 양자화를 수행하고 모델의 테스트 정확도에 대한 영향을 평가하기:

```
yarn quantize-and-evaluate-fashion-mnist
```

## MobileNetV2 양자화 데모

앞선 세 개의 데모와 달리 MobilNetV2 데모는 모델 훈련 단계가 없습니다.
대신 케라스 애플리케이션으로 모델을 로드한 다음 TensorFlow.js 포맷으로 변경하여 양자와화 평가를 수행합니다.

MobilNetV2에 양자화를 적용하지 않은 모델과 양자화 모델을 [ImageNet](http://www.image-net.org/)
데이터셋에 있는 1,000개 이미지에서 평가합니다.
이 샘플은 https://github.com/ajschumacher/imagen 을 기반으로 합니다.

다음 명령으로 이런 작업을 모두 수행할 수 있습니다:

```sh
yarn quantize-and-evaluate-MobileNetV2
```
